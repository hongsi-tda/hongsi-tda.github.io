## Today I Studied 2020.04.01

* K-means clustering 
  - [k평균 알고리즘 wikipedia](https://ko.wikipedia.org/wiki/K-%ED%8F%89%EA%B7%A0_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)
  - 표준 알고리즘의 실행 과정 : 데이터 오브젝트 중 무작위로 뽑고 -> 가장 가까이 있는 평균값으로 묶음 -> 중심점으로 평균값 재조정 -> 수렴할 때 까지 이 과정을 반복 
  - [scikit-learn KMeans Clustering](https://scikit-learn.org/stable/modules/clustering.html#k-means)


* Encoding for categorical variables
  - [Medium Label Encoder vs. One Hot Encoder in Machine Learning](https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621)
  - label encoding : 한 컬럼에 범주에 따라 숫자를 지정해 변환해줌 
    - 단점 : 숫자의 크기에 따라 순서(또는 중요도)로 인식함 이를 보완하는 방법이 one hot encoding
    
    
  - one hot encoding : 컬럼 내에서 있는 범주형 변수의 갯수 만큼 새로운 컬럼을 생성해 해당 범주에 속하면 1, 아니면 0으로 표시함
  - [StackExchange When to use One Hot Encoding vs LabelEncoder vs DictVectorizor?](https://datascience.stackexchange.com/questions/9443/when-to-use-one-hot-encoding-vs-labelencoder-vs-dictvectorizor)
    - label encoding은 숫자를 순서로 인식해서 값 사이 계산이 이뤄지는 알고리즘을 사용할때는 부적절하지만 
      - decision tree, random forest 알고리즘 사용시에는 괜찮음
    - one hot encoding이 안전한 방식이긴 하지만 curse of dementionality 문제가 발생할수 있고
      - 위 경우에는 PCA를 통한 demationality reduction을 거쳐야함
