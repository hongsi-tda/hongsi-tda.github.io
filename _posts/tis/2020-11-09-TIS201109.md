---
title:  "TIS 201109"
excerpt:  "Airflow Basic"

categories:
  - TIS
tags:
  - Tools
  - DataEngineering
---

## Today I Studied 2020.11.09

### Airflow Basic

#### [Airflow란?](https://bcho.tistory.com/1184)

* **여러개의 태스크 연결해서 수행**해야 하는 경우에 활용(DB ETL 작업과 비슷한 흐름)<br>
e.g. 머신러닝 : 로 데이터 - 전처리 - 학습 데이터 - 학습된 모델(저장) - 예측 - 예측 결과

* 데이터 워크 플로우 관리 도구 
e.g. 에코시스템 우지(oozie), rundeck, 스포티파이의 luigi, 링크드인의 Azkaban<br>

* Airbnb에서 개발된 도구, 파이썬으로 코드 작성 가능, 여러 머신 분산 수행 가능

#### Airflow 시작하기

* airflow 설치
```pip install airflow```

* MySQL 연결
```% airflow initdb```

* 웹콘솔 기동
```airflow webserver -p 8080```

* Airflow 코드
  - airflow DAG(Directed Acyclic Graph) : 하나의 워크 플로우
  - Operator : 정의되는 작업 함수
  - Task : dag 상에서 실제로 워크 플로우 상 정의되어 호출 되었을 때
  - 코드 작성 예시 :

````python 
from airflow import DAG
from airflow.operators.bash_operator import BashOperator
from airflow.operators.dummy_operator import DummyOperator
from airflow.operators.python_operator import PythonOperator
from datetime import datetime,timedelta


dag = DAG('hello-airflow',description='Hello airflow DAG',
          schedule_interval = '*/5 0 * * *',
          start_date=datetime(2017,07,01),catchup=False)
# DAG(이름, description=설명, schedule_interval=실행주기, start_date=시작일자)
# DAG는 반드시 전역 변수로 지정(sub DAG의 경우, 지역 변수로 지정 가능)

def print_hello():
    return 'Hello Airflow'


python_task = PythonOperator(
                    task_id='python_operator',
                    python_callable = print_hello,
                    dag = dag)
# PythonOperator : 파이썬 코드 실행할 태스크

bash_task = BashOperator(
        task_id='print_date',
        bash_command='date',
        dag=dag)
# BashOperator : 쉘 커맨드 실행할 태스크 

bash_task.set_downstream(python_task)````


#### 등록(배포)

* dag_folder에 저장 : $AIRFLOW_HOME/airflow.cfg, $AIRFLOW_HOME/dags(폴더)
  - 위 코드를 해당 디렉토리에 복사

* dag 잘 등록되었는지 확인
```airflow list_dags```

* 태스크까지 확인
```airflow list_tasks 이름```

#### 테스트
* 태스크 단위로 가능
```airflow test {DAG ID} {태스크 ID} {실행날짜}```

#### 실행
* airflow scheduler 실행
```airflow scheduler```

#### 로그 모니터링
* ```$AIRFLOW_HOME/logs```에 저장됨
* 각각의 dag 이름으로, 이름 안에 태스크명으로 된 서브 디렉토리 있고, 그 안에 시간대별 로그 있음
* ```$AIRFLOW_HOME/logs/hello-airflow/print_date/{날짜및시간} 파일명```

#### 웹 콘솔로 모니터링
* Graph View : dag 구조 보여줌
* Tree View : 성공/실패 여부, 실행 결과 세부 메뉴, View Log(태스크 별)
* Task Duration : 수행 시간(태스크 별), 일정한 지 확인 가능
* Task Tries : 수행 횟수(즉, retry 모니터링)
* Gantt : 수행 순서에 따라 소모된 시간을 간트 차트로 보여줌, 병목 구간 파악에 용이

