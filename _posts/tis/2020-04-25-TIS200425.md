---
title:  "TIS 200425"
excerpt:  "분류 모델링에서 데이터 불균형 문제 해결"

categories:
  - TIS
tags:
  - 머신러닝
  
toc: true
toc_sticky: true
---

## Today I Studied 2020.04.25

### 분류 모델링에서 데이터 불균형 문제 해결

1. Random Under-Sampling
(임의로 제거함으로써) major class의 비중을 낮추는 방법


장점 :
* 훈련 데이터의 크기를 줄여 실행시간 및 용량 측면에서 이점을 볼 수 있다.


단점 :
* 분류 모델링 시 유용하게 사용될 정보가 유실 될 수 있다.
* 샘플링 된 훈련 데이터가 편향(biased)되거나 모집단을 대표하지 않을 수 있다.
* 위 이유로 시험 데이터로 모델 돌렸을때 이상한 결과가 도출될 수 있다.


2. Random Over-Sampling
(임의로 복제함으로써) minor class의 비중을 높이는 방법


장점 :
* Under-Sampling 보다 정보의 손실이 적다.
* Under-Sampling 보다 성능이 뛰어나다.


단점 : 
* Minor class를 예측하는 모델링일때 과적합(over-fitting)의 우려가 있다. 


3. Synthetic Minority Over-sampling Technique, SMOTE
Over-Sampling의 과적합 문제를 피하기 위해, 기존 minor class에서 subset 추출 -> 거기서 유사한 instance 추출 -> 이를 기존 데이터에 더해 훈련 시행


장점 : 
* 정보 손실의 우려가 없다.
* Over-Sampling의 과적합 문제를 해결할 수 있다.


단점 : 
* 인접한 major class의 instance는 고려하지 않아 클래스가 겹치거나 노이즈를 발생시킬 수 있다.
* 고차원 데이터에 효율적이지 않다.

4. Modified Synthetic Minority Over-sampling Technique, MSMOTE
Minor class의 근원적 분포와 잠재적 노이즈를 고려하지 않은 SMOTE의 단점을 보완하기 위해, minor class를 instance와 훈련 데이터 간 거리를 계산해 세 그룹(security/safe samples, border samples, latent noise sample)으로 나눈다. 
* Security/safe samples는 모델의 성능을 높이고, noise samples는 모델의 성능을 낮추고, border samples는 그 둘에 속하지 않는 애매모호한 데이터 그룹이다.
* 무작위로 데이터를 생성하는 SMOTE와 달리, MSMOTE는 security 위주로 만들고 latent에 대해서는 아무것도 하지 않는다.


* 참고 :
   - https://joonable.tistory.com/m/27
   - https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/
   - https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets
 


 

